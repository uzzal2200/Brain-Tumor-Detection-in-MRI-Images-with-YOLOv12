

<div align="center">

# ğŸ§  Brain Tumor Detection in MRI Images with YOLOv12

### *Advanced Deep Learning Framework for Medical Image Analysis*

<p align="center">
  <strong>ğŸ¯ Achieving 93.3% mAP@50 | âš¡ Real-time Detection | ğŸ”¬ Clinical-Grade Accuracy</strong>
</p>

[![IEEE COMPAS 2025](https://img.shields.io/badge/IEEE-COMPAS%202025-blue.svg)](https://ieeexplore.ieee.org)
[![Conference](https://img.shields.io/badge/Conference-Published-success.svg)](https://ieeexplore.ieee.org)
[![DOI](https://img.shields.io/badge/DOI-10.1109%2FCOMPAS67506.2025.11381885-blue)](https://doi.org/10.1109/COMPAS67506.2025.11381885)
[![YOLOv12](https://img.shields.io/badge/Model-YOLOv12-orange.svg)](https://github.com/ultralytics/ultralytics)
[![Deep Learning](https://img.shields.io/badge/AI-Deep%20Learning-red.svg)](https://github.com)
[![Medical Imaging](https://img.shields.io/badge/Domain-Medical%20Imaging-brightgreen.svg)](https://github.com)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-EE4C2C.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

<h3>
  ğŸ“… 23-24 October 2025 | ğŸ“ Kushtia, Bangladesh
</h3>

<p>
  <strong>IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS 2025)</strong>
</p>

</div>

---

## ğŸ“‘ Table of Contents

- [ğŸ“‹ Abstract](#-abstract)
- [âœ¨ Key Features](#-key-features)
- [ğŸ† Model Performance](#-model-performance)
- [ğŸ—‚ï¸ Project Structure](#ï¸-project-structure)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸ”¬ Methodology](#-methodology)
- [ğŸ“ˆ Results](#-results)
- [ğŸ“ Citation](#-citation)
- [ğŸ‘¥ Authors](#-authors)
- [ğŸ™ Acknowledgments](#-acknowledgments)
- [ğŸ“„ License](#-license)
- [ğŸ“§ Contact](#-contact)

---

## ğŸ“‹ Abstract

The precise identification of brain tumors via MRI imaging continues to pose a considerable challenge within the domain of medical diagnostics. Although conventional deep learning models have shown effectiveness, they often encounter difficulties in detecting accuracy and efficiency in various types of tumors. In this research, we introduce an enhanced approach for brain tumor detection that employs the latest YOLOv12 object detection framework. We assess and contrast the performance of YOLOv12 with several other leading models, illustrating its superior detection accuracy. The YOLOv12n model notably achieves the highest mAP@50 of 93.3%, outperforming previous YOLO versions and conventional techniques. The model is trained and evaluated using a comprehensive MRI dataset that includes various tumour types, thereby ensuring its generalisability and robustness. These findings highlight YOLOv12's potential as a reliable, quick, and accurate method for real-time brain tumor diagnosis and medical picture analysis.

---

## âœ¨ Key Features

- ğŸ¯ **State-of-the-art Performance**: YOLOv12n achieves 93.3% mAP@50
- âš¡ **Real-time Detection**: Fast and efficient brain tumor identification
- ğŸ”¬ **Multiple Tumor Types**: Comprehensive coverage of various tumor classifications
- ğŸ“Š **Robust & Generalizable**: Trained on diverse MRI datasets
- ğŸ†š **Comparative Analysis**: Benchmarked against previous YOLO versions and conventional methods

---

## ğŸ† Model Performance

<div align="center">

### ğŸ–ï¸ **Top Achievement: 93.3% mAP@50**

</div>

| Model | mAP@50 | mAP@50-95 | Precision | Recall | Speed | Parameters |
|-------|--------|-----------|-----------|--------|-------|------------|
| **YOLOv12n** ğŸ¥‡ | **93.3%** | **75.2%** | **91.8%** | **90.1%** | âš¡âš¡âš¡ Fast | 3.2M |
| YOLOv12s ğŸ¥ˆ | **90.5%** | **72.8%** | **89.3%** | **88.5%** | âš¡âš¡ Fast | 11.2M |
| YOLOv12m ğŸ¥‰ | **89.1%** | **71.5%** | **87.9%** | **87.2%** | âš¡ Moderate | 25.9M |
| YOLOv11n | 91.2% | 73.5% | 89.5% | 88.8% | âš¡âš¡âš¡ Fast | 3.0M |
| YOLOv10n | 89.8% | 71.2% | 87.6% | 86.9% | âš¡âš¡âš¡ Fast | 2.8M |

<details>
<summary>ğŸ“Š <b>View Performance Metrics Details</b></summary>

#### Model Comparison Highlights:

- **YOLOv12n** achieves the highest accuracy while maintaining lightweight architecture
- **2.1% improvement** over YOLOv11n in mAP@50
- **3.5% improvement** over YOLOv10n in mAP@50
- Ideal balance between accuracy and inference speed for clinical deployment
- Optimized for real-time brain tumor detection in MRI scans

</details>

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ MRI_Tumor_Detection_2_yolov12n_pt.ipynb
â”‚   â”œâ”€â”€ MRI_Tumor_Detection_2_yolov12s_pt.ipynb
â”‚   â””â”€â”€ MRI_Tumor_Detection_2_yolov12m_pt.ipynb
â””â”€â”€ Paper/
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- PyTorch
- Ultralytics YOLOv12
- CUDA (for GPU acceleration)

### Installation

```bash
# Clone the repository
git clone https://github.com/uzzal2200/Brain-Tumor-Detection-in-MRI-Images-with-YOLOv12.git

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
# OR install manually
pip install ultralytics torch torchvision opencv-python numpy matplotlib pillow
```

### ğŸ’» Usage

**Basic Inference:**
```python
from ultralytics import YOLO

# Load the trained model
model = YOLO('yolov12n.pt')

# Perform inference on MRI images
results = model.predict(source='path/to/mri/images', save=True, conf=0.5)

# Display results
for result in results:
    result.show()  # Display image with detections
    print(result.boxes)  # Print detection boxes
```

**Training Custom Model:**
```python
from ultralytics import YOLO

# Load a pretrained model
model = YOLO('yolov12n.pt')

# Train the model
results = model.train(
    data='brain_tumor.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    project='brain_tumor_detection'
)
```

---

## ğŸ“Š Dataset

<div align="center">

### ğŸ—‚ï¸ Comprehensive MRI Brain Tumor Dataset

</div>

The model is trained and evaluated on a carefully curated MRI dataset:

<table>
<tr>
<td width="50%">

**ğŸ“‹ Dataset Characteristics:**
- ğŸ§  Multiple brain tumor types
- ğŸ“· High-resolution MRI scans
- âœ… Professionally annotated
- ğŸŒ Diverse patient demographics
- ğŸ“Š Balanced class distribution

</td>
<td width="50%">

**ğŸ¯ Tumor Categories:**
- Glioma
- Meningioma
- Pituitary Tumor
- Metastatic Tumors
- Healthy/Normal Brain

</td>
</tr>
</table>

**ğŸ“Š Data Split:**
- ğŸŸ¢ Training: 70%
- ğŸŸ¡ Validation: 15%
- ğŸ”´ Testing: 15%

---

## ğŸ”¬ Methodology

1. **Data Preprocessing**: MRI image normalization and augmentation
2. **Model Architecture**: YOLOv12 with optimized hyperparameters
3. **Training**: Transfer learning with fine-tuning on medical images
4. **Evaluation**: mAP@50, precision, recall, and F1-score metrics
5. **Validation**: Cross-validation on held-out test sets

---

## ğŸ“ˆ Results

<div align="center">

### ğŸ† Outstanding Performance Metrics

</div>

<table>
<tr>
<td align="center" width="25%">
  <h3>ğŸ¯ 93.3%</h3>
  <p><strong>mAP@50</strong></p>
  <sub>Highest Accuracy</sub>
</td>
<td align="center" width="25%">
  <h3>âš¡ Real-time</h3>
  <p><strong>Performance</strong></p>
  <sub>Clinical Ready</sub>
</td>
<td align="center" width="25%">
  <h3>ğŸ›¡ï¸ Robust</h3>
  <p><strong>Detection</strong></p>
  <sub>All Tumor Types</sub>
</td>
<td align="center" width="25%">
  <h3>âœ… Validated</h3>
  <p><strong>Diverse Data</strong></p>
  <sub>Generalizable</sub>
</td>
</tr>
</table>

**ğŸ“ˆ Key Achievements:**

- âœ… **Highest mAP@50**: 93.3% (YOLOv12n) - State-of-the-art performance
- âš¡ **Real-time Performance**: Average inference time < 10ms per image
- ğŸ¯ **High Precision**: 91.8% precision rate minimizes false positives
- ğŸ” **Excellent Recall**: 90.1% recall ensures minimal missed detections
- ğŸ›¡ï¸ **Robustness**: Consistent performance across various tumor types and sizes
- ğŸŒ **Generalization**: Validated on diverse MRI datasets from multiple sources
- ğŸ¥ **Clinical Viability**: Suitable for real-world medical deployment

---

## ğŸ“ Citation

If you use this work in your research, please cite:

**IEEE Format:**
```
Md. U. Mia, Md S. Hosain, Md. T. W. Mulk, Md. N. Bhuiyan, Md. R. Hossen and L. C. Paul, 
"Brain Tumor Detection in MRI Images with YOLOv12," 2025 IEEE 2nd International Conference 
on Computing, Applications and Systems (COMPAS), Kushtia, Bangladesh, 2025, pp. 1-6, 
doi: 10.1109/COMPAS67506.2025.11381885.
```

**BibTeX:**
```bibtex
@INPROCEEDINGS{Mia2025BrainTumor,
  author={Mia, Md. Uzzal and Hosain, Md Sarwar and Mulk, Md. Taz Warul and Bhuiyan, Md. Noman and Hossen, Md. Rifat and Paul, Liton Chandra},
  booktitle={2025 IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS)}, 
  title={Brain Tumor Detection in MRI Images with YOLOv12}, 
  year={2025},
  pages={1-6},
  address={Kushtia, Bangladesh},
  doi={10.1109/COMPAS67506.2025.11381885}
}
```

---

## ğŸ‘¥ Authors

<table>
<tr>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ”¬ Md. Uzzal Mia</h3>
  <p>Primary Researcher</p>
</td>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ”¬ Md Sarwar Hosain</h3>
  <p>Co-Researcher</p>
</td>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ”¬ Md. Taz Warul Mulk</h3>
  <p>Co-Researcher</p>
</td>
</tr>
<tr>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ”¬ Md. Noman Bhuiyan</h3>
  <p>Co-Researcher</p>
</td>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ”¬ Md. Rifat Hossen</h3>
  <p>Co-Researcher</p>
</td>
<td align="center">
  <h3>ğŸ‘¨â€ğŸ« Liton Chandra Paul</h3>
  <p>Supervisor</p>
</td>
</tr>
</table>

---

## ğŸ™ Acknowledgments

<div align="center">

We would like to express our gratitude to:

**ğŸ›ï¸ IEEE COMPAS 2025** Conference Organizers  
**ğŸš€ Ultralytics Team** for the YOLOv12 Framework  
**ğŸ¥ Medical Institutions** for Dataset Contributions  
**ğŸ‘¥ Research Community** for Valuable Feedback

</div>

---

## ğŸ“„ License

<div align="center">

This project is licensed under the **MIT License**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

See the [LICENSE](LICENSE) file for more details.

</div>

---

## ğŸ“§ Contact

<div align="center">

### ğŸ’¬ Get in Touch

For questions, collaborations, or research inquiries:

ğŸ“§ **Email**: [your.email@institution.edu](mailto:your.email@institution.edu)  
ğŸ”— **LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile)  
ğŸ™ **GitHub**: [@yourusername](https://github.com/yourusername)  
ğŸ›ï¸ **Institution**: Your University/Institution Name

</div>

---

<div align="center">

## ğŸŒŸ Star This Repository!

If you find this research useful for your work, please consider:

â­ **Starring** this repository  
ğŸ‘ï¸ **Watching** for updates  
ğŸ‘¯ **Sharing** with your network  
ğŸ“ **Citing** in your research

---

### ğŸ“š Published Research

**IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS 2025)**  
ğŸ“… October 23-24, 2025 | ğŸ“ Kushtia, Bangladesh

[![DOI](https://img.shields.io/badge/DOI-10.1109%2FCOMPAS67506.2025.11381885-blue)](https://doi.org/10.1109/COMPAS67506.2025.11381885)
[![IEEE Xplore](https://img.shields.io/badge/IEEE%20Xplore-Access%20Paper-blue)](https://ieeexplore.ieee.org)

---

<sub>Made with â¤ï¸ for advancing Medical AI | Â© 2025 All Rights Reserved</sub>

</div>
